install.packages("kernlab")
library(kernlab)
data(spam)
# Vamos escolher 0 para nonspam e 1 para spam
Y = as.numeric(spam[, ncol(spam)])-1 # (O R atribui 2 a spam e 1 a nonspam)
X = spam[ ,-ncol(spam)]
gl = glm(Y ~ ., data=X,family=binomial)
summary(gl)
proba = predict(gl,type="response")
predicted.spam = as.numeric( proba > 0.5)
table(predicted.spam,Y)
# Agora claro erra muito mais e ainda assim atribui como spam 12 que eram non-spam!
n = length(Y)
s=sample(1:n)
q=round(0.70*n)
train=s[1:q]
test=s[(q+1):n]
gl = glm(Y[train] ~., data=X[train,],family=binomial)
proba.train = predict(gl,newdata=X[train,],type="response")
proba.test = predict(gl,newdata=X[test,],type="response")
predicted.spam.train = as.numeric(proba.train > 0.99)
predicted.spam.test = as.numeric(proba.test > 0.99)
table(predicted.spam.train, Y[train])
table(predicted.spam.test, Y[test])
#
# Ele classificou 194 spams como non spam e, mais importante, 122 nonspam como spam!!!
# agora para 0.99
predicted.spam = as.numeric( proba>0.99)
table(predicted.spam,Y)
library(MASS)
lda.res = lda(x=X[train,],grouping=Y[train])
proba.lda = predict(lda.res,newdata=X[test,])$posterior[,2]
predicted.spam.lda = as.numeric(proba.lda > 0.99)
# Curvas ROC; em vez de 0.5 e 0.99 apenas, vamos usar muitos cut-off entre 0 e 1
cvec = seq(0.001,0.999,length=1000)
cvec = seq(0.001,0.999,length=1000)
specif= numeric(length(cvec))
sensit= numeric(length(cvec))
for (cc in 1:length(cvec)){
sensit[cc]= sum( proba.lda > cvec[cc] & Y[test]==1)/sum(Y[test]==1)
specif[cc]= sum( proba.lda<=cvec[cc] & Y[test]==0)/sum(Y[test]==0)
}
plot(specif,sensit,main="LDA=linha preta e RL= linha vermelha",
+ xlab="SPECIFICITY",ylab="SENSITIVITY",type="l",lwd=2)
plot(specif,sensit,main="LDA=linha preta e RL= linha vermelha", xlab="SPECIFICITY",ylab="SENSITIVITY",type="l",lwd=2)
for (cc in 1:length(cvec)){
sensit[cc]= sum( proba.test> cvec[cc] & Y[test]==1)/sum(Y[test]==1)
specif[cc]= sum( proba.test<=cvec[cc] & Y[test]==0)/sum(Y[test]==0)
}
lines(specif,sensit,col="red",type="l",lwd=2)
